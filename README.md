# ğŸ· Whisper-Based Offline Transcription Tool

## ğŸ“ Overview

This project is a Python-based offline transcription tool built around OpenAIâ€™s [`whisper-large-v3`](https://huggingface.co/openai/whisper-large-v3) automatic speech recognition (ASR) model. It converts audio and video content into high-quality text transcriptions without relying on any cloud service â€” ensuring privacy, full control, and offline performance.

Designed using **object-oriented software architecture**, this tool is ideal for developers with C# or Java backgrounds who prefer structured, maintainable code.

---

## ğŸŒŸ Purpose

This tool solves the need for a **private, automated, offline transcription system**. It supports a clean CLI interface, folder-based input/output, and extensible modules for future upgrades.

---

## ğŸ§± Features

* ğŸ” Transcribe `.mp4`, `.mp3`, `.wav`, and more using `whisper-large-v3`
* ğŸ“‚ Scan all files in an `unprocessed/` folder
* ğŸ“„ Output `.txt` files to a `processed/` folder with matching filenames
* ğŸ”§ OOP design: easily extensible with future features (e.g., SRT, language override)
* ğŸ’¡ Simple but professional folder layout and script interface

---

## ğŸ“ Folder Structure

```plaintext
J:\repos\huggingface_transcribe\
â”œâ”€â”€ env\                         # Python virtual environment
â”œâ”€â”€ transcribe.py                # CLI entry point (main script)
â”œâ”€â”€ transcriber.py               # TranscriptionEngine class
â”œâ”€â”€ file_manager.py              # FileManager class
â”œâ”€â”€ unprocessed\                 # Drop files here for transcription
â”‚   â”œâ”€â”€ myvideo.mp4
â”‚   â””â”€â”€ meeting.wav
â”œâ”€â”€ processed\                   # Output transcripts
â”‚   â”œâ”€â”€ myvideo.txt
â”‚   â””â”€â”€ meeting.txt
â”œâ”€â”€ README.md                    # Project overview and instructions
â””â”€â”€ DESIGN_GOALS.md              # Software design rationale
```

---

## ğŸ”„ How It Works

### ğŸ” Workflow Summary

1. **Place input files** in the `unprocessed/` folder:

   * Supported formats: `.mp4`, `.mp3`, `.wav`, `.m4a`, etc.

2. **Run the transcription script** from the root directory:

   ```bash
   python transcribe.py
   ```

3. The script:

   * Loads the `whisper-large-v3` model once
   * Transcribes every media file in the `unprocessed/` folder
   * Saves each transcript to `processed/` with the same base filename and a `.txt` extension

4. **Result**:

   * Human-readable `.txt` transcripts are available in the `processed/` folder
   * You can archive, edit, or further analyze them as needed

---

## ğŸš€ Getting Started

### âœ… Prerequisites

* Python **3.10 or higher**
* FFmpeg installed and available in PATH
* `pip` (Python package manager)
* Optional: install Python to `E:\` if you're low on `C:\` space

### ğŸ“¦ Install Dependencies

From your working folder:

```bash
cd J:\repos\huggingface_transcribe
python -m venv env
.\env\Scripts\activate         # PowerShell
# OR
env\Scripts\activate.bat      # Command Prompt

pip install git+https://github.com/openai/whisper.git
pip install ffmpeg-python
```

---

## âš™ï¸ Configuration

Currently hardcoded values (can be refactored later):

* **Input folder**: `unprocessed/`
* **Output folder**: `processed/`
* **Model**: `"large-v3"` (You may switch to `"medium"` or `"small"` for lower RAM)

Planned support for:

* Language override
* Config files or CLI flags

---

## ğŸ§  Future Enhancements

| Feature                                     | Status     |
| ------------------------------------------- | ---------- |
| `.srt` or `.vtt` subtitle export            | ğŸ”œ Planned |
| Language override support                   | ğŸ”œ Planned |
| Speaker diarization                         | ğŸ”œ Planned |
| Progress bar or logging system              | ğŸ”œ Planned |
| Batch resumption (skipping processed files) | ğŸ”œ Planned |
| Simple GUI or web interface                 | ğŸ”œ Planned |

---

## ğŸ’¡ Philosophy

This is not just a one-off script â€” it's a modular, thoughtfully structured tool. Built with OOP principles to support:

* Unit testing
* Reusability
* Easy onboarding for new developers

> â€œBuild it as if you're handing it off to your future self as a teammate.â€

---

## ğŸ” License

This tool uses the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0).
The Whisper model is provided by [OpenAI](https://github.com/openai/whisper), also under Apache 2.0.

---

## ğŸ™Œ Credits

* [OpenAI Whisper](https://github.com/openai/whisper) â€“ automatic speech recognition
* [Hugging Face](https://huggingface.co/openai/whisper-large-v3) â€“ model hosting
* FFmpeg â€“ audio preprocessing
* Python community â€“ tools and ecosystem
