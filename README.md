# ðŸŽ§ Whisper-Based Offline Transcription Tool

## ðŸ“ Overview

This project is a Python-based offline transcription tool built around OpenAIâ€™s [`whisper-large-v3`](https://huggingface.co/openai/whisper-large-v3) automatic speech recognition (ASR) model. It converts audio and video content into high-quality text transcriptions without relying on any cloud service â€” ensuring privacy, full control, and offline performance.

Designed using **object-oriented software architecture**, this tool is ideal for developers with C# or Java backgrounds who prefer structured, maintainable code.

It is intended for:

* Researchers and educators working with recorded interviews or lectures
* Media producers managing large libraries of audio/video content
* Developers and data scientists who want to integrate ASR into workflows
* Anyone needing fast, offline transcription without exposing sensitive data

---

## ðŸ§± Features

* ðŸ” Transcribe `.mp4`, `.mp3`, `.wav`, and more using `whisper-medium` (default)
* ðŸ“‚ Scan all files in an `unprocessed/` folder
* ðŸ“„ Output `.txt` files to a `processed/` folder with matching filenames
* ðŸ”§ OOP design: easily extensible with future features (e.g., SRT, language override)
* ðŸ’¡ Simple but professional folder layout and script interface

---

## ðŸ“ Folder Structure

```plaintext
J:\repos\huggingface_transcribe\
â”œâ”€â”€ env\                         # Python virtual environment
â”œâ”€â”€ src\                         # Source code modules
â”‚   â”œâ”€â”€ transcribe.py            # CLI entry point
â”‚   â”œâ”€â”€ transcriber.py           # TranscriptionEngine class
â”‚   â””â”€â”€ file_manager.py          # FileManager class
â”œâ”€â”€ unprocessed\                 # Drop files here for transcription
â”œâ”€â”€ processed\                   # Output transcripts
â”œâ”€â”€ README.md                    # Project overview and usage
â”œâ”€â”€ agent.md                     # Agent behavior and workflow rules
â”œâ”€â”€ design_goals.md              # Software architecture principles
â””â”€â”€ build.md                     # Development checklist
```

---

## ðŸ”„ How It Works

### ðŸ” Workflow Summary

1. **Place input files** in the `unprocessed/` folder:

   * Supported formats: `.mp4`, `.mp3`, `.wav`, `.m4a`, etc.

2. **Run the transcription script** from the `src/` directory:

   ```bash
   python src/transcribe.py
   ```

3. The script:

   * Loads the `whisper-medium` model by default
   * Transcribes every media file in the `unprocessed/` folder
   * Saves each transcript to `processed/` with the same base filename and a `.txt` extension

4. **Result**:

   * Human-readable `.txt` transcripts are available in the `processed/` folder
   * You can archive, edit, or further analyze them as needed

---

## ðŸš€ Getting Started

### âœ… Prerequisites

* Python **3.10 or higher**
* FFmpeg installed and available in PATH
* `pip` (Python package manager)
* Optional: install Python to `E:\` if you're low on `C:\` space

### ðŸ“¦ Install Dependencies

From your project root folder:

```bash
cd J:\repos\huggingface_transcribe
python -m venv env
.\env\Scripts\activate         # PowerShell
# OR
env\Scripts\activate.bat      # Command Prompt

pip install git+https://github.com/openai/whisper.git
pip install ffmpeg-python
```

---

## âš™ï¸ Configuration

* **Input folder**: `unprocessed/`
* **Output folder**: `processed/`
* **Model**: `"medium"` by default; switchable via future config or CLI

---

## ðŸ§  Future Enhancements

| Feature                                     | Status     |
| ------------------------------------------- | ---------- |
| `.srt` or `.vtt` subtitle export            | ðŸ”œ Planned |
| Language override support                   | ðŸ”œ Planned |
| Speaker diarization                         | ðŸ”œ Planned |
| Progress bar or logging system              | ðŸ”œ Planned |
| Batch resumption (skipping processed files) | ðŸ”œ Planned |
| Simple GUI or web interface                 | ðŸ”œ Planned |

---

## ðŸ’¡ Philosophy

This is not just a one-off script â€” it's a modular, thoughtfully structured tool. Built with OOP principles to support:

* Unit testing
* Reusability
* Easy onboarding for new developers

> â€œBuild it as if you're handing it off to your future self as a teammate.â€

---

## ðŸ” License

This tool uses the [Apache 2.0 License](https://www.apache.org/licenses/LICENSE-2.0).
The Whisper model is provided by [OpenAI](https://github.com/openai/whisper), also under Apache 2.0.

---

## ðŸ™Œ Credits

* [OpenAI Whisper](https://github.com/openai/whisper) â€“ automatic speech recognition
* [Hugging Face](https://huggingface.co/openai/whisper-large-v3) â€“ model hosting
* FFmpeg â€“ audio preprocessing
* Python community â€“ tools and ecosystem

---

> This `README.md` now reflects the streamlined planning structure. All relevant implementation context is consolidated in `agent.md`, `build.md`, and `design_goals.md`.
